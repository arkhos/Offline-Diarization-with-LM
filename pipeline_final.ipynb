{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07626097-5fba-40b8-8320-c3cf37ed15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import whisper\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from whisper.audio import pad_or_trim, log_mel_spectrogram, N_FRAMES\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "from openai import AzureOpenAI\n",
    "from datasets import load_dataset\n",
    "from pyannote.core import Annotation, Segment\n",
    "from pyannote.metrics.diarization import DiarizationPurity, DiarizationCoverage\n",
    "\n",
    "\n",
    "# from config.config import load_config\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af681642-d5f6-4b51-8cd9-b8596486a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyannoteProcessor:\n",
    "    \"\"\"\n",
    "    Class to perform speaker diarization using the Pyannote library.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pipeline = Pipeline.from_pretrained(\n",
    "           \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=\"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\",\n",
    "        )\n",
    "\n",
    "    def perform_diarization(self, audio_file_path):\n",
    "        self.pipeline.to(torch.device('cuda')) # switch to gpu\n",
    "\n",
    "        # Hardcoding the number of speakers\n",
    "        diarization = self.pipeline(audio_file_path, num_speakers=2)\n",
    "\n",
    "        with open (\"sample.rttm\", \"w\") as rttm:\n",
    "          diarization.write_rttm(rttm)\n",
    "        \n",
    "\n",
    "    def rttm_to_dataframe(self, rttm_file_path):\n",
    "        columns = [\n",
    "            \"Type\",\n",
    "            \"File ID\",\n",
    "            \"Channel\",\n",
    "            \"Start Time\",\n",
    "            \"Duration\",\n",
    "            \"Orthography\",\n",
    "            \"Confidence\",\n",
    "            \"Speaker\",\n",
    "            \"x\",\n",
    "            \"y\",\n",
    "        ]\n",
    "        data = []\n",
    "\n",
    "        with open(rttm_file_path, \"r\") as rttm_file:\n",
    "            lines = rttm_file.readlines()\n",
    "\n",
    "        data = [line.strip().split() for line in lines]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df = df.drop([\"x\", \"y\", \"Orthography\", \"Confidence\"], axis=1)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff96623d-a910-40a7-9dd6-27e7d4643ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhisperProcessor:\n",
    "    def __init__(self):\n",
    "        # Initialize the Whisper model\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(self.device)\n",
    "        self.model = whisper.load_model(\"large-v2\").to(self.device)\n",
    "        # torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "        # model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "        # model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        #     model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "        # )\n",
    "        # model.to(device)\n",
    "\n",
    "        # processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "        # pipe = pipeline(\n",
    "        #     \"automatic-speech-recognition\",\n",
    "        #     model=model,\n",
    "        #     tokenizer=processor.tokenizer,\n",
    "        #     feature_extractor=processor.feature_extractor,\n",
    "        #     max_new_tokens=128,\n",
    "        #     chunk_length_s=25,\n",
    "        #     batch_size=16,\n",
    "        #     torch_dtype=torch_dtype,\n",
    "        #     device=device,\n",
    "        # )\n",
    "\n",
    "\n",
    "    def transcribe_audio_with_whisper(self, audio_file, detected_language):\n",
    "        \"\"\"\n",
    "        Transcribes an audio segment using the Whisper ASR model.\n",
    "\n",
    "        Args:\n",
    "            audio_file (str): Path to the audio file.\n",
    "            detected_language (str): Detected language of the audio.\n",
    "\n",
    "        Returns:\n",
    "            dict: Transcription result containing text and other information.\n",
    "        \"\"\"\n",
    "        result = self.model.transcribe(\n",
    "            audio_file, language=detected_language, fp16=False, temperature = (0.8, 1.0)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "        # Whisper predicts the language of the source audio automatically. \n",
    "        # If the source audio language is known a-priori, it can be passed as an argument to the pipeline:\n",
    "\n",
    "        # result = pipe(audio_file, generate_kwargs={\"language\": \"english\"})\n",
    "        # return result[\"text\"]\n",
    "\n",
    "    def detect_audio_language(self, audio) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Detects the language of an audio segment using the Whisper ASR model.\n",
    "\n",
    "        Args:\n",
    "            audio (AudioSegment): Audio segment to detect language from.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, float]: Detected language and confidence.\n",
    "        \"\"\"\n",
    "        mel_segment = pad_or_trim(log_mel_spectrogram(audio), N_FRAMES).to(\n",
    "            self.model.device\n",
    "        )\n",
    "        _, probs = self.model.detect_language(mel_segment)\n",
    "        detected_language = max(probs, key=probs.get)\n",
    "        confidence = probs[detected_language]\n",
    "\n",
    "        return detected_language, confidence\n",
    "\n",
    "    def process_audio_segment(\n",
    "        self, audio_file, start_time, end_time, detected_language\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Processes an audio segment within a specified time range.\n",
    "\n",
    "        Args:\n",
    "            audio_file (str): Path to the audio file.\n",
    "            start_time (int): Start time of the segment in milliseconds.\n",
    "            end_time (int): End time of the segment in milliseconds.\n",
    "            detected_language (str): Detected language of the audio segment.\n",
    "\n",
    "        Returns:\n",
    "            str: Collapsed transcript for the processed audio segment.\n",
    "        \"\"\"\n",
    "        start_time = float(start_time * 1000)\n",
    "        end_time = float(end_time * 1000)\n",
    "\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        audio_segment = audio[start_time:end_time]\n",
    "        \n",
    "        audio_segment_path = f\"audio_segment_{start_time}.wav\"\n",
    "        audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "        \n",
    "        # Transcribe the audio segment\n",
    "        transcription_result = self.transcribe_audio_with_whisper(\n",
    "            audio_segment_path, detected_language\n",
    "        )\n",
    "        whisper_transcript = transcription_result[\"text\"]\n",
    "\n",
    "        # Split the transcript into segments\n",
    "        segments = whisper_transcript.split(\"\\n\")\n",
    "\n",
    "        # Collapse the segments\n",
    "        collapsed_transcript = self.collapse_segments(segments)\n",
    "\n",
    "        # Delete the temporary audio segment file\n",
    "        os.remove(audio_segment_path)\n",
    "\n",
    "        return collapsed_transcript\n",
    "\n",
    "    def collapse_segments(self, transcript_segments):\n",
    "        \"\"\"\n",
    "        Collapses individual words and spaces in the transcript segments.\n",
    "\n",
    "        Args:\n",
    "            transcript_segments (list): List of transcript segments.\n",
    "\n",
    "        Returns:\n",
    "            str: Collapsed transcript with words and spaces combined.\n",
    "        \"\"\"\n",
    "        segment_counter = 0\n",
    "        collapsed_segments = []\n",
    "\n",
    "        for segment in transcript_segments:\n",
    "            if segment.startswith(\"Segment\"):\n",
    "                segment_counter += 1\n",
    "                collapsed_segments.append(segment)\n",
    "            else:\n",
    "                words = segment.split()\n",
    "                for word in words:\n",
    "                    collapsed_segments.append(word)\n",
    "                    collapsed_segments.append(\" \")\n",
    "\n",
    "        collapsed_transcript = \"\".join(collapsed_segments)\n",
    "        return collapsed_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c28e4ce-8e43-4281-b946-24cf3b844d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_GPT4 = AzureOpenAI(\n",
    "    azure_endpoint = \"https://dlcru-east-us2.openai.azure.com/\",\n",
    "    api_version = \"2023-03-15-preview\",\n",
    "    api_key = \"37798b94e5ac418c9a31ba3f1dc81acf\",\n",
    ")\n",
    "\n",
    "model_GPT4 = \"dlcru-gpt4\"\n",
    "\n",
    "\n",
    "client_GPT35_turbo = AzureOpenAI(\n",
    "    azure_endpoint =  \"https://gpt3test-dlcru.openai.azure.com/\",\n",
    "    api_version = \"2023-03-15-preview\",\n",
    "    api_key =  \"41d57743bbf94908a07d7cb75dc6799c\"\n",
    ")\n",
    "\n",
    "model_GPT35_turbo = \"dlcru-gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce5972e-5440-4830-ab79-cb1984eb3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, client, model):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "\n",
    "    def create_prompt(self, text, shot_type):\n",
    "        prompt_zero_shot = f\"\"\"In the speaker diarization transcript below, some words are potentially misplaced.\n",
    "            Please correct those words and move them to the right speaker.\n",
    "            Directly show the corrected transcript without explaining what changes were made or why you\n",
    "            made those changes\n",
    "            \n",
    "            \"{text}\"\n",
    "            \"\"\"\n",
    "        prompt_one_shot = f\"\"\"In the speaker diarization transcript below, some words are potentially misplaced. There are only 2 speakers. \n",
    "            Please correct those words and move them to the right speaker. For example, given this input transcript,\n",
    "            <spk:1> How are you doing today? I <spk:2> am doing very well. How was everything at the\n",
    "            <spk:1> party? Oh, the party? It was awesome. We had lots of fun. Good <spk:2> to hear!\n",
    "            The correct output transcript should be:\n",
    "            <spk:1> How are you doing today? <spk:2> I am doing very well. How was everything at the\n",
    "            party? <spk:1> Oh, the party? It was awesome. We had lots of fun. <spk:2> Good to hear!\n",
    "            Now, please correct the transcript below.\\n\n",
    "            \n",
    "             \"{text}\"\n",
    "            \"\"\"\n",
    "        if shot_type == 'zero_shot':\n",
    "            return prompt_zero_shot\n",
    "        elif shot_type == 'one_shot':\n",
    "            return prompt_one_shot\n",
    "\n",
    "\n",
    "    def get_completion(self, text, shot_type, temperature=0):\n",
    "        prompt = self.create_prompt(text, shot_type)\n",
    "        \n",
    "        message_objects = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Answer shortly and only what you are asked.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=message_objects,\n",
    "                    temperature=temperature\n",
    "                )\n",
    "                return completion.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                if '429' in str(e):  # Check if the error is due to rate limit (429 status code)\n",
    "                    retry_after = 9  # Retry after 9 seconds as per the error message\n",
    "                    print(f\"Rate limit exceeded. Retrying after {retry_after} seconds.\")\n",
    "                    time.sleep(retry_after)\n",
    "                else:\n",
    "                    raise  # Re-raise other exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0737080c-17cd-4b26-a320-3dcfea4591be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    def __init__(self, pyannote_processor, whisper_processor):\n",
    "        self.pyannote = pyannote_processor\n",
    "        self.whisper = whisper_processor\n",
    "\n",
    "    def extract_speakers(self, text):\n",
    "        labels = []\n",
    "        speaker_count = {}\n",
    "        current_label = 1  # Start with label 1\n",
    "    \n",
    "        lines = text.strip().split(':')\n",
    "    \n",
    "        for line in lines:\n",
    "            speaker_id = line.split(':')[0].strip()\n",
    "            if speaker_id not in speaker_count:\n",
    "                speaker_count[speaker_id] = 1\n",
    "            else:\n",
    "                speaker_count[speaker_id] += 1\n",
    "    \n",
    "            labels.append(current_label)\n",
    "            current_label = 2 if current_label == 1 else 1  # Alternate between 1 and 2\n",
    "    \n",
    "        return labels\n",
    "\n",
    "    def process_and_append_to_csv(self, dataset, output_csv_path):\n",
    "        column_names = [\"audio_number\", \"text_GT\", \"diarization_without_LM\", \n",
    "                                                    \"diarization_35_turbo_zero_shot\", \"diarization_35_turbo_one_shot\",\n",
    "                                                    \"diarization_4_zero_shot\", \"diarization_4_one_shot\",\n",
    "                        \"speakers_GT\", \"speakers_without_LM\", \n",
    "                                                    \"speakers_35_turbo_zero_shot\", \"speakers_35_turbo_one_shot\",\n",
    "                                                    \"speakers_4_zero_shot\", \"speakers_4_one_shot\"]\n",
    "\n",
    "        with open(output_csv_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "            csv_writer = csv.writer(\n",
    "                csv_file, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
    "            )\n",
    "\n",
    "            if os.path.getsize(output_csv_path) == 0:\n",
    "                csv_writer.writerow(column_names)\n",
    "\n",
    "            for audio_number, row in enumerate(tqdm(dataset, desc=\"Processing dataset\")):\n",
    "                audio_data = row['audio']\n",
    "                speakers_GT = row['speakers']\n",
    "\n",
    "                # Remove consecutive repetitions from speakers_GT\n",
    "                filtered_GT = [speakers_GT[0]]  # Start with the first element\n",
    "\n",
    "                for i in range(1, len(speakers_GT)):\n",
    "                    if speakers_GT[i] != filtered_GT[-1]:  # If current element is different from the last added element\n",
    "                        filtered_GT.append(speakers_GT[i])\n",
    "                \n",
    "                                \n",
    "                audio_array = audio_data['array']\n",
    "                sampling_rate = audio_data['sampling_rate']\n",
    "                \n",
    "                # Normalize audio array to the range [-32768, 32767] (16-bit PCM range)\n",
    "                audio_array_normalized = np.int16(audio_array * 32767)\n",
    "                \n",
    "                # Specify the output WAV file path\n",
    "                output_wav_file = os.path.join(\n",
    "                    os.path.dirname(output_csv_path),\n",
    "                    os.path.splitext(output_csv_path)[0] + '_audio.wav'\n",
    "                )\n",
    "\n",
    "                sf.write(output_wav_file, audio_array, sampling_rate, subtype='PCM_16')\n",
    "\n",
    "\n",
    "                # Making the Ground Truth of the words with Whisper hardcoding the language\n",
    "                whisper_GT = self.whisper.transcribe_audio_with_whisper(\n",
    "                    output_wav_file, \"english\"\n",
    "                )\n",
    "\n",
    "                text_GT = whisper_GT[\"text\"]\n",
    "\n",
    "                try:\n",
    "                    # Perform Pyannote diarization\n",
    "                    print(\"Starting Pyannote...\")\n",
    "                    self.pyannote.perform_diarization(output_wav_file)\n",
    "                    print(\"Finished Pyannote\")\n",
    "\n",
    "                    rttm_file_path = \"sample.rttm\"\n",
    "                    df = self.pyannote.rttm_to_dataframe(rttm_file_path)\n",
    "                    df = df.astype({\"Start Time\": \"float\"})\n",
    "                    df = df.astype({\"Duration\": \"float\"})\n",
    "                    df[\"Utterance\"] = None\n",
    "                    df[\"End Time\"] = df[\"Start Time\"] + df[\"Duration\"]\n",
    "\n",
    "                    silence_gap_pairs = []\n",
    "\n",
    "                    for ind in df.index:\n",
    "                        start_time = df[\"Start Time\"][ind]\n",
    "                        end_time = df[\"End Time\"][ind]\n",
    "                        speaker = df[\"Speaker\"][ind]\n",
    "\n",
    "                        silence_gap_pairs.append((start_time, end_time, speaker))\n",
    "\n",
    "                    attributes_list = []\n",
    "\n",
    "                    current_start, current_end, current_speaker = silence_gap_pairs[0]\n",
    "\n",
    "                    for start, end, speaker in silence_gap_pairs[1:]:\n",
    "                        if speaker == current_speaker:\n",
    "                            current_end = end\n",
    "                        else:\n",
    "                            attributes_list.append((current_start, current_end, current_speaker, \"\"))\n",
    "                            current_start, current_end, current_speaker = start, end, speaker\n",
    "\n",
    "                    print(\"Starting Whisper...\")\n",
    "                    for i, (start, end, speaker, text) in enumerate(attributes_list):\n",
    "                        transcript = self.whisper.process_audio_segment(\n",
    "                            output_wav_file, start, end, \"english\"  # Replace \"english\" with detected language\n",
    "                        )\n",
    "                        attributes_list[i] = (start, end, speaker, transcript)\n",
    "\n",
    "                    print(\"Finished Whisper\")\n",
    "\n",
    "                    diarization_without_LM = \" \".join([f\"{speaker}: {text}\" for _, _, speaker, text in attributes_list])\n",
    "\n",
    "                    # call the LM to correct the diarization output\n",
    "                    print(\"Starting 3.5 turbo...\")\n",
    "                    llm_gtp35_turbo = LLM(client_GPT35_turbo, model_GPT35_turbo)\n",
    "                    \n",
    "                    print(\"zero shot\")\n",
    "                    diarization_35_turbo_zero_shot = llm_gtp35_turbo.get_completion(text=diarization_without_LM, shot_type='zero_shot')\n",
    "                    \n",
    "                    print(\"one shot\")\n",
    "                    diarization_35_turbo_one_shot = llm_gtp35_turbo.get_completion(text=diarization_without_LM, shot_type='one_shot')\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    print(\"Starting 4...\")\n",
    "                    llm_gpt4 = LLM(client_GPT4, model_GPT4)\n",
    "\n",
    "                    print(\"zero shot\")\n",
    "                    diarization_4_zero_shot = llm_gpt4.get_completion(text=diarization_without_LM, shot_type='zero_shot')\n",
    "\n",
    "                    print(\"one shot\")\n",
    "                    diarization_4_one_shot = llm_gpt4.get_completion(text=diarization_without_LM, shot_type='one_shot')\n",
    "\n",
    "\n",
    "\n",
    "                    # compute the speakers for DiarizationPurity and DiarizationCoverage \n",
    "                    speakers_without_LM = self.extract_speakers(diarization_without_LM)\n",
    "                    speakers_35_turbo_zero_shot = self.extract_speakers(diarization_35_turbo_zero_shot)\n",
    "                    speakers_35_turbo_one_shot = self.extract_speakers(diarization_35_turbo_one_shot)\n",
    "                    speakers_4_zero_shot = self.extract_speakers(diarization_4_zero_shot)\n",
    "                    speakers_4_one_shot = self.extract_speakers(diarization_4_one_shot)\n",
    "            \n",
    "\n",
    "\n",
    "                    \n",
    "                    csv_writer.writerow([audio_number, text_GT, \n",
    "                                                                diarization_without_LM, \n",
    "                                                                diarization_35_turbo_zero_shot, diarization_35_turbo_one_shot,\n",
    "                                                                diarization_4_zero_shot, diarization_4_one_shot,\n",
    "                                                        filtered_GT,\n",
    "                                                                speakers_without_LM,\n",
    "                                                                speakers_35_turbo_zero_shot, speakers_35_turbo_one_shot,\n",
    "                                                                speakers_4_zero_shot, speakers_4_one_shot\n",
    "                                        ])\n",
    "                    \n",
    "                    os.remove(output_wav_file)\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    # break\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred for audio {audio_number}: {e}\")\n",
    "\n",
    "                # Flush the buffer to the file\n",
    "                csv_file.flush()\n",
    "\n",
    "    def process_dataset(self, output_csv_path):\n",
    "        ds = load_dataset(\"talkbank/callhome\", \"eng\")\n",
    "        dataset = ds['data']\n",
    "\n",
    "        self.process_and_append_to_csv(dataset, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e466fd-c233-47fd-bad1-d822c972e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcdeonise-test-c7d94e68    \u001b[m  Mon Jun 24 01:49:03 2024  \u001b[1m\u001b[30m550.54.15\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 28°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24564\u001b[m MB |\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   0%|          | 0/140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   1%|          | 1/140 [03:47<8:46:39, 227.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   1%|▏         | 2/140 [11:11<13:36:50, 355.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   2%|▏         | 3/140 [13:43<9:59:02, 262.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   3%|▎         | 4/140 [14:58<7:06:53, 188.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for audio 3: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n",
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   4%|▎         | 5/140 [21:30<9:48:43, 261.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   4%|▍         | 6/140 [28:27<11:42:35, 314.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   5%|▌         | 7/140 [34:25<12:08:55, 328.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   6%|▌         | 8/140 [38:21<10:58:24, 299.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   6%|▋         | 9/140 [42:42<10:27:04, 287.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   7%|▋         | 10/140 [48:16<10:53:20, 301.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   8%|▊         | 11/140 [56:23<12:50:26, 358.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   9%|▊         | 12/140 [1:02:26<12:47:24, 359.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:   9%|▉         | 13/140 [1:08:17<12:35:40, 357.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  10%|█         | 14/140 [1:43:14<30:53:36, 882.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for audio 13: Request timed out.\n",
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  11%|█         | 15/140 [1:49:51<25:33:53, 736.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  11%|█▏        | 16/140 [1:57:59<22:47:23, 661.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  12%|█▏        | 17/140 [2:01:48<18:09:36, 531.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  13%|█▎        | 18/140 [2:39:02<35:21:13, 1043.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for audio 17: Request timed out.\n",
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  14%|█▎        | 19/140 [2:46:05<28:48:07, 856.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  14%|█▍        | 20/140 [2:53:16<24:17:45, 728.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  15%|█▌        | 21/140 [3:00:19<21:03:40, 637.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  16%|█▌        | 22/140 [3:04:29<17:04:27, 520.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  16%|█▋        | 23/140 [3:13:57<17:23:23, 535.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  17%|█▋        | 24/140 [3:22:52<17:14:15, 534.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  18%|█▊        | 25/140 [3:26:42<14:10:06, 443.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  19%|█▊        | 26/140 [3:30:01<11:43:03, 370.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  19%|█▉        | 27/140 [3:37:15<12:13:12, 389.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  20%|██        | 28/140 [3:43:46<12:07:54, 389.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  21%|██        | 29/140 [3:52:44<13:23:14, 434.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  21%|██▏       | 30/140 [4:01:20<14:00:58, 458.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  22%|██▏       | 31/140 [4:09:04<13:56:13, 460.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  23%|██▎       | 32/140 [4:18:31<14:46:35, 492.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  24%|██▎       | 33/140 [4:21:52<12:02:22, 405.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  24%|██▍       | 34/140 [4:27:57<11:34:08, 392.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  25%|██▌       | 35/140 [4:37:42<13:08:41, 450.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  26%|██▌       | 36/140 [4:47:48<14:21:51, 497.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  26%|██▋       | 37/140 [4:51:50<12:02:01, 420.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  27%|██▋       | 38/140 [5:00:03<12:31:50, 442.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  28%|██▊       | 39/140 [5:09:50<13:37:27, 485.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  29%|██▊       | 40/140 [5:26:38<17:50:35, 642.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  29%|██▉       | 41/140 [5:34:08<16:04:36, 584.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  30%|███       | 42/140 [5:41:04<14:32:38, 534.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  31%|███       | 43/140 [5:44:43<11:50:31, 439.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  31%|███▏      | 44/140 [5:54:29<12:53:36, 483.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  32%|███▏      | 45/140 [6:12:10<17:19:49, 656.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  33%|███▎      | 46/140 [6:16:22<13:58:55, 535.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for audio 45: Error code: 400 - {'error': {'message': \"Sorry! We've encountered an issue with repetitive patterns in your prompt. Please try again with a different prompt.\", 'type': 'invalid_request_error', 'param': 'prompt', 'code': 'invalid_prompt'}}\n",
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  34%|███▎      | 47/140 [6:25:33<13:57:02, 540.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  34%|███▍      | 48/140 [6:31:25<12:21:29, 483.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  35%|███▌      | 49/140 [6:40:44<12:47:33, 506.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  36%|███▌      | 50/140 [6:48:54<12:32:01, 501.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  36%|███▋      | 51/140 [6:55:54<11:47:23, 476.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  37%|███▋      | 52/140 [6:59:04<9:33:15, 390.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  38%|███▊      | 53/140 [7:04:08<8:49:08, 364.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  39%|███▊      | 54/140 [7:13:00<9:54:53, 415.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  39%|███▉      | 55/140 [7:22:01<10:41:24, 452.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  40%|████      | 56/140 [7:30:06<10:47:31, 462.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  41%|████      | 57/140 [7:39:10<11:13:26, 486.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  41%|████▏     | 58/140 [7:47:35<11:12:45, 492.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  42%|████▏     | 59/140 [7:51:49<9:28:19, 420.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pyannote...\n",
      "Finished Pyannote\n",
      "Starting Whisper...\n",
      "Finished Whisper\n",
      "Starting 3.5 turbo...\n",
      "zero shot\n",
      "one shot\n",
      "Starting 4...\n",
      "zero shot\n",
      "one shot\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "!gpustat\n",
    "\n",
    "diarization = PyannoteProcessor()\n",
    "stt = WhisperProcessor()\n",
    "audio_processor = AudioProcessor(diarization, stt)\n",
    "\n",
    "audio_processor.process_dataset(\"/root/diarizare/transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1cedd-2d71-463e-a765-bcaee654171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordMetrics:\n",
    "    @staticmethod\n",
    "    def preprocess_transcript(transcript):\n",
    "        # Define regex pattern to match speaker labels\n",
    "        pattern = r'SPEAKER_\\d+:'\n",
    "        \n",
    "        # Split transcript using regex pattern\n",
    "        segments = re.split(pattern, transcript)\n",
    "        \n",
    "        # Clean up segments (remove empty strings and leading/trailing spaces)\n",
    "        segments = [seg.strip() for seg in segments if seg.strip()]\n",
    "        \n",
    "        # Extract speaker labels\n",
    "        speaker_labels = re.findall(pattern, transcript)\n",
    "        \n",
    "        return segments, speaker_labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_metrics(transcript_GT, transcript_hypothesis):\n",
    "        # Preprocess ground truth and hypothesis transcripts\n",
    "        segments_GT, speakers_GT = WordMetrics.preprocess_transcript(transcript_GT)\n",
    "        segments_hypothesis, speakers_hypothesis = WordMetrics.preprocess_transcript(transcript_hypothesis)\n",
    "        \n",
    "        # Calculate WDER\n",
    "        def calculate_WDER(segments_GT, segments_hypothesis, speakers_GT, speakers_hypothesis):\n",
    "            SIS = 0\n",
    "            CIS = 0\n",
    "            S = 0\n",
    "            C = 0\n",
    "            \n",
    "            # Determine the maximum length to iterate over\n",
    "            max_length = min(len(segments_GT), len(segments_hypothesis), len(speakers_GT), len(speakers_hypothesis))\n",
    "            \n",
    "            for i in range(max_length):\n",
    "                # Skip if indices are out of range\n",
    "                if i >= len(segments_GT) or i >= len(segments_hypothesis) or i >= len(speakers_GT) or i >= len(speakers_hypothesis):\n",
    "                    continue\n",
    "                \n",
    "                speaker_h = speakers_hypothesis[i]\n",
    "                speaker_g = speakers_GT[i]\n",
    "                \n",
    "                words_h = segments_hypothesis[i].split()\n",
    "                words_g = segments_GT[i].split()\n",
    "                \n",
    "                # Count substitutions\n",
    "                for wh, wg in zip(words_h, words_g):\n",
    "                    if wh != wg:\n",
    "                        S += 1\n",
    "                        if speaker_h != speaker_g:\n",
    "                            SIS += 1\n",
    "                    else:\n",
    "                        C += 1\n",
    "                        if speaker_h != speaker_g:\n",
    "                            CIS += 1\n",
    "            \n",
    "            if (S + C) > 0:\n",
    "                WDER = (SIS + CIS) / (S + C)\n",
    "            else:\n",
    "                WDER = 0.0\n",
    "            \n",
    "            return WDER\n",
    "        \n",
    "        # Calculate cpWER\n",
    "        def calculate_cpWER(segments_GT, segments_hypothesis):\n",
    "            def compute_wer(ref, hyp):\n",
    "                # Function to compute Word Error Rate (WER)\n",
    "                ref_words = ref.split()\n",
    "                hyp_words = hyp.split()\n",
    "    \n",
    "                # Create a matrix to store edits\n",
    "                edits = [[0] * (len(hyp_words) + 1) for _ in range(len(ref_words) + 1)]\n",
    "    \n",
    "                # Initialize the first row and column\n",
    "                for i in range(len(ref_words) + 1):\n",
    "                    edits[i][0] = i\n",
    "                for j in range(len(hyp_words) + 1):\n",
    "                    edits[0][j] = j\n",
    "    \n",
    "                # Fill the matrix\n",
    "                for i in range(1, len(ref_words) + 1):\n",
    "                    for j in range(1, len(hyp_words) + 1):\n",
    "                        if ref_words[i - 1] == hyp_words[j - 1]:\n",
    "                            edits[i][j] = edits[i - 1][j - 1]\n",
    "                        else:\n",
    "                            substitute = edits[i - 1][j - 1] + 1\n",
    "                            insert = edits[i][j - 1] + 1\n",
    "                            delete = edits[i - 1][j] + 1\n",
    "                            edits[i][j] = min(substitute, insert, delete)\n",
    "    \n",
    "                return edits[len(ref_words)][len(hyp_words)] / len(ref_words)\n",
    "    \n",
    "            # Concatenate all segments for reference and hypothesis\n",
    "            ref_concatenated = ' '.join(segments_GT)\n",
    "            hyp_concatenated = ' '.join(segments_hypothesis)\n",
    "    \n",
    "            # Compute WER for all permutations\n",
    "            cpWER = compute_wer(ref_concatenated, hyp_concatenated)\n",
    "    \n",
    "            return cpWER\n",
    "        \n",
    "        # Compute WDER\n",
    "        WDER = calculate_WDER(segments_GT, segments_hypothesis, speakers_GT, speakers_hypothesis)\n",
    "        \n",
    "        # Compute cpWER\n",
    "        cpWER = calculate_cpWER(segments_GT, segments_hypothesis)\n",
    "        \n",
    "        return WDER, cpWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94951d-6d72-4fcc-9ec0-60316ab03432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakersMetrics:\n",
    "    @staticmethod\n",
    "    def convert_to_annotation(speaker_labels):\n",
    "        annotation = Annotation()  # Assuming Annotation class is defined elsewhere\n",
    "        current_speaker = None\n",
    "        current_start = None\n",
    "        \n",
    "        for i, speaker_label in enumerate(speaker_labels):\n",
    "            if i == 0 or speaker_label != speaker_labels[i - 1]:\n",
    "                # End previous segment\n",
    "                if current_speaker is not None:\n",
    "                    annotation[Segment(current_start, i)] = current_speaker\n",
    "                # Start new segment\n",
    "                current_speaker = speaker_label\n",
    "                current_start = i\n",
    "        \n",
    "        # Add last segment\n",
    "        if current_speaker is not None:\n",
    "            annotation[Segment(current_start, len(speaker_labels))] = current_speaker\n",
    "        \n",
    "        return annotation\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_metrics(reference_labels, hypothesis_labels):\n",
    "        # Convert speaker labels to annotations\n",
    "        reference_annotation = SpeakersMetrics.convert_to_annotation(reference_labels)\n",
    "        hypothesis_annotation = SpeakersMetrics.convert_to_annotation(hypothesis_labels)\n",
    "        \n",
    "        # Initialize purity and coverage metrics\n",
    "        purity = DiarizationPurity()  # Assuming DiarizationPurity and DiarizationCoverage are defined elsewhere\n",
    "        coverage = DiarizationCoverage()\n",
    "        \n",
    "        # Compute metrics\n",
    "        purity_score = purity(reference_annotation, hypothesis_annotation)\n",
    "        coverage_score = coverage(reference_annotation, hypothesis_annotation)\n",
    "        \n",
    "        return purity_score, coverage_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ea70f-ccc6-4755-9077-d41b1debcad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to compute all metrics and update DataFrame\n",
    "def compute_all_metrics(df):\n",
    "    for suffix in [\"without_LM\", \"35_turbo_zero_shot\", \"35_turbo_one_shot\", \"4_zero_shot\", \"4_one_shot\"]:\n",
    "        # Compute WDER and cpWER using WordMetrics\n",
    "        df[f\"WDER_{suffix}\"], df[f\"cpWER_{suffix}\"] = zip(*df.apply(lambda row: WordMetrics.compute_metrics(row['text_GT'], row[f'diarization_{suffix}']), axis=1))\n",
    "        \n",
    "        # Compute DiarizationPurity and DiarizationCoverage using SpeakersMetrics\n",
    "        df[f\"DiarizationPurity_{suffix}\"], df[f\"DiarizationCoverage_{suffix}\"] = zip(*df.apply(lambda row: SpeakersMetrics.compute_metrics(row['speakers_GT'], row[f'speakers_{suffix}']), axis=1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load transcripts.csv into a pandas DataFrame\n",
    "df = pd.read_csv('/root/diarizare/transcripts.csv')\n",
    "\n",
    "# Compute all metrics and update DataFrame\n",
    "df = compute_all_metrics(df)\n",
    "\n",
    "# Save the updated DataFrame with metrics columns\n",
    "df.to_csv('/root/diarizare/transcripts_with_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5795d507-b28f-4e37-8ff5-014c54183b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    WDER     cpWER  DiarizationPurity  DiarizationCoverage\n",
      "without_LM           0.0  0.730058           0.407282             0.340947\n",
      "35_turbo_zero_shot   0.0  0.792664           0.600697             0.550390\n",
      "35_turbo_one_shot    0.0  0.739704           0.469220             0.395633\n",
      "4_zero_shot          0.0  0.721414           0.522158             0.467135\n",
      "4_one_shot           0.0  0.721169           0.566625             0.508129\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/root/diarizare/transcripts_with_metrics.csv')\n",
    "\n",
    "# Define the metrics and methods\n",
    "metrics = [\"WDER\", \"cpWER\", \"DiarizationPurity\", \"DiarizationCoverage\"]\n",
    "methods = [\"without_LM\", \"35_turbo_zero_shot\", \"35_turbo_one_shot\", \"4_zero_shot\", \"4_one_shot\"]\n",
    "\n",
    "# Initialize an empty dictionary to store summary data\n",
    "summary_data = {}\n",
    "\n",
    "# Calculate the mean for each metric for each method\n",
    "for metric in metrics:\n",
    "    summary_data[metric] = [df[f\"{metric}_{method}\"].mean() for method in methods]\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_df = pd.DataFrame(summary_data, index=methods)\n",
    "\n",
    "# Print the summary table\n",
    "print(summary_df)\n",
    "\n",
    "# Optionally, save the summary DataFrame to a CSV file\n",
    "summary_df.to_csv('summary_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5792ca01-a750-4bab-87a4-18201b6e0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details for diarization without LM and the diarization with the lowest cpWER:\n",
      "Diarization without LM:\n",
      "    audio_number                             diarization_without_LM  \\\n",
      "61            66  SPEAKER_01: Is the program geared primarily to...   \n",
      "\n",
      "    cpWER_without_LM  \n",
      "61          0.278231  \n",
      "Diarization with the lowest cpWER (cpWER_4_zero_shot):\n",
      "    audio_number                            diarization_4_zero_shot  \\\n",
      "61            66  \"SPEAKER_01: Is the program geared primarily t...   \n",
      "\n",
      "    cpWER_4_zero_shot  \n",
      "61           0.268917  \n",
      "\n",
      "Details for diarization without LM and the diarization with the highest cpWER:\n",
      "Diarization without LM:\n",
      "    audio_number                             diarization_without_LM  \\\n",
      "71            76  SPEAKER_01: Oh so you can get involved in that...   \n",
      "\n",
      "    cpWER_without_LM  \n",
      "71          1.809478  \n",
      "Diarization with the highest cpWER (cpWER_4_zero_shot):\n",
      "    audio_number                            diarization_4_zero_shot  \\\n",
      "71            76  \"SPEAKER_01: Oh so you can get involved in tha...   \n",
      "\n",
      "    cpWER_4_zero_shot  \n",
      "71           1.768859  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = 'transcripts_with_metrics.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the cpWER columns for each method\n",
    "cpWER_columns = [\"cpWER_35_turbo_zero_shot\", \"cpWER_35_turbo_one_shot\", \"cpWER_4_zero_shot\", \"cpWER_4_one_shot\"]\n",
    "\n",
    "# Find the minimum and maximum cpWER values and the corresponding columns\n",
    "min_cpWER = df[cpWER_columns].min().min()\n",
    "max_cpWER = df[cpWER_columns].max().max()\n",
    "min_cpWER_column = df[cpWER_columns].min().idxmin()\n",
    "max_cpWER_column = df[cpWER_columns].max().idxmax()\n",
    "\n",
    "# Find the rows with the minimum and maximum cpWER values\n",
    "min_cpWER_row = df[df[min_cpWER_column] == min_cpWER]\n",
    "max_cpWER_row = df[df[max_cpWER_column] == max_cpWER]\n",
    "\n",
    "# Print the relevant diarization details for the lowest cpWER\n",
    "print(\"Details for diarization without LM and the diarization with the lowest cpWER:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(min_cpWER_row[['audio_number', 'diarization_without_LM', 'cpWER_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the lowest cpWER ({min_cpWER_column}):\")\n",
    "print(min_cpWER_row[['audio_number', min_cpWER_column.replace('cpWER', 'diarization'), min_cpWER_column]])\n",
    "\n",
    "# Print the relevant diarization details for the highest cpWER\n",
    "print(\"\\nDetails for diarization without LM and the diarization with the highest cpWER:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(max_cpWER_row[['audio_number', 'diarization_without_LM', 'cpWER_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the highest cpWER ({max_cpWER_column}):\")\n",
    "print(max_cpWER_row[['audio_number', max_cpWER_column.replace('cpWER', 'diarization'), max_cpWER_column]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0274ad-d9d3-4c3e-8187-7209ab9f3f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details for diarization without LM and the diarization with the lowest DiarizationPurity:\n",
      "Diarization without LM:\n",
      "    audio_number                             diarization_without_LM  \\\n",
      "25            28  SPEAKER_00: all good where  SPEAKER_01: though...   \n",
      "\n",
      "    DiarizationPurity_without_LM  \n",
      "25                      0.384058  \n",
      "Diarization with the lowest DiarizationPurity (DiarizationPurity_35_turbo_zero_shot):\n",
      "    audio_number                     diarization_35_turbo_zero_shot  \\\n",
      "25            28  SPEAKER_00: all good where \\nSPEAKER_01: thoug...   \n",
      "\n",
      "    DiarizationPurity_35_turbo_zero_shot  \n",
      "25                              0.384804  \n",
      "\n",
      "Details for diarization without LM and the diarization with the highest DiarizationPurity:\n",
      "Diarization without LM:\n",
      "     audio_number                             diarization_without_LM  \\\n",
      "9              10  SPEAKER_01: The thing is, Dogo is kind of anno...   \n",
      "11             12  SPEAKER_01: But other than that, she knows she...   \n",
      "13             15  SPEAKER_01: get it sometime before you came ho...   \n",
      "16             19  SPEAKER_01: Great. What should we talk about? ...   \n",
      "20             23  SPEAKER_00:  SPEAKER_01: Yeah. Until you find ...   \n",
      "27             30  SPEAKER_01: Wow, very nice. It's really sweet....   \n",
      "28             31  SPEAKER_01: How you doing? Okay good, how are ...   \n",
      "30             33  SPEAKER_01: In the envelope that I sent to you...   \n",
      "32             35  SPEAKER_00:  SPEAKER_01: and I-and Eileen told...   \n",
      "42             46  SPEAKER_01: So how are you?  SPEAKER_00: S  SP...   \n",
      "43             47  SPEAKER_01: uh... because i was going to ask y...   \n",
      "45             49  SPEAKER_01: I know Cynthia through Rachel, so ...   \n",
      "50             54  SPEAKER_01: And they're going to be here.... w...   \n",
      "51             55  SPEAKER_00: as you say, but I mean for her, it...   \n",
      "52             56  SPEAKER_01: But umm guess what happened? Wow. ...   \n",
      "53             57  SPEAKER_01: these are all that stuff that is a...   \n",
      "57             61  SPEAKER_01: This is what I want to tell you. W...   \n",
      "65             70  SPEAKER_01: It was very, I remember when we we...   \n",
      "69             74  SPEAKER_01: no jq like happening ticket might ...   \n",
      "72             77  SPEAKER_01: Well, this is perfect timing becau...   \n",
      "74             79  SPEAKER_00:  SPEAKER_01: So tell me a little b...   \n",
      "75             80  SPEAKER_01: How are ya? I'm doing great man, i...   \n",
      "76             81  SPEAKER_01: Hello? How is Bubby? What happened...   \n",
      "78             83  SPEAKER_01: I don't think he gave me an addres...   \n",
      "82             87  SPEAKER_01:  SPEAKER_00: So I was like, he was...   \n",
      "87             93  SPEAKER_01: but anyway the global method that ...   \n",
      "90             96  SPEAKER_01: Oh my gosh. Yeah. You know, so you...   \n",
      "91             97  SPEAKER_01: mm and  SPEAKER_00:  SPEAKER_01: a...   \n",
      "92             98  SPEAKER_01: if you've anything that you think ...   \n",
      "93             99  SPEAKER_01: Yeah Oh come on like there's any d...   \n",
      "97            103  SPEAKER_01: And he totally noticed everything....   \n",
      "99            105  SPEAKER_00: Good, thank you.  SPEAKER_01: Than...   \n",
      "100           106  SPEAKER_01: and guess who called here last nig...   \n",
      "102           108  SPEAKER_01:  SPEAKER_00: got no beer. No that ...   \n",
      "110           117  SPEAKER_01: I'm doing good. I'll go on a Susan...   \n",
      "118           125  SPEAKER_01: The thing about it... The city is ...   \n",
      "120           127  SPEAKER_00:  SPEAKER_01: So tell me. I mean it...   \n",
      "122           129  SPEAKER_00: veganly actually not and not hundr...   \n",
      "127           134  SPEAKER_00: Not until after mid-January, or ac...   \n",
      "129           136  SPEAKER_01: But he said he's glad that he did ...   \n",
      "\n",
      "     DiarizationPurity_without_LM  \n",
      "9                        0.403646  \n",
      "11                       0.408451  \n",
      "13                       0.393548  \n",
      "16                       0.408805  \n",
      "20                       0.402899  \n",
      "27                       0.403727  \n",
      "28                       0.403194  \n",
      "30                       0.412121  \n",
      "32                       0.402299  \n",
      "42                       0.404040  \n",
      "43                       0.409524  \n",
      "45                       0.405556  \n",
      "50                       0.405622  \n",
      "51                       0.407407  \n",
      "52                       0.405405  \n",
      "53                       0.403628  \n",
      "57                       0.402863  \n",
      "65                       0.403361  \n",
      "69                       0.404531  \n",
      "72                       0.405303  \n",
      "74                       0.404598  \n",
      "75                       0.405498  \n",
      "76                       0.401180  \n",
      "78                       0.407018  \n",
      "82                       0.404531  \n",
      "87                       0.404558  \n",
      "90                       0.404762  \n",
      "91                       0.402685  \n",
      "92                       0.404444  \n",
      "93                       0.405797  \n",
      "97                       0.406061  \n",
      "99                       0.404040  \n",
      "100                      0.405797  \n",
      "102                      0.402036  \n",
      "110                      0.405128  \n",
      "118                      0.407960  \n",
      "120                      0.403153  \n",
      "122                      0.403509  \n",
      "127                      0.403382  \n",
      "129                      0.404580  \n",
      "Diarization with the highest DiarizationPurity (DiarizationPurity_35_turbo_zero_shot):\n",
      "     audio_number                     diarization_35_turbo_zero_shot  \\\n",
      "9              10  Sorry, I cannot provide the corrected transcri...   \n",
      "11             12  Sorry, I cannot provide the corrected transcri...   \n",
      "13             15  Sorry, I cannot provide the corrected transcri...   \n",
      "16             19  SPEAKER_01: Great. What should we talk about? ...   \n",
      "20             23  I'm sorry, I cannot provide the corrected tran...   \n",
      "27             30  Sorry, I cannot provide the corrected transcri...   \n",
      "28             31  Sorry, I cannot provide the corrected transcri...   \n",
      "30             33  \"SPEAKER_01: In the envelope that I sent to yo...   \n",
      "32             35  Sorry, I cannot provide the corrected transcri...   \n",
      "42             46                                   No changes made.   \n",
      "43             47  Sorry, I cannot provide the corrected transcri...   \n",
      "45             49  SPEAKER_01: I know Cynthia through Rachel, so ...   \n",
      "50             54  Sorry, I cannot provide the corrected transcri...   \n",
      "51             55  Sorry, I cannot provide the corrected transcri...   \n",
      "52             56  Sorry, I cannot provide the corrected transcri...   \n",
      "53             57  I'm sorry, I cannot provide the corrected tran...   \n",
      "57             61  Sorry, I cannot provide the corrected transcri...   \n",
      "65             70  Sorry, I cannot provide the corrected transcri...   \n",
      "69             74  I'm sorry, I cannot provide the corrected tran...   \n",
      "72             77  SPEAKER_01: Well, this is perfect timing becau...   \n",
      "74             79  I'm sorry, I cannot provide the corrected tran...   \n",
      "75             80  Sorry, I cannot provide the corrected transcri...   \n",
      "76             81  I'm sorry, I cannot provide the corrected tran...   \n",
      "78             83  I'm sorry, I cannot provide the corrected tran...   \n",
      "82             87  Sorry, I cannot provide the corrected transcri...   \n",
      "87             93  Sorry, I cannot provide the corrected transcri...   \n",
      "90             96  I'm sorry, I cannot provide the corrected tran...   \n",
      "91             97  Sorry, I cannot provide the corrected transcri...   \n",
      "92             98  Sorry, I cannot provide the corrected transcri...   \n",
      "93             99  SPEAKER_01: Yeah, oh come on, like there's any...   \n",
      "97            103  Sorry, I cannot provide the corrected transcri...   \n",
      "99            105  I'm sorry, I cannot provide the corrected tran...   \n",
      "100           106  I'm sorry, I cannot provide the corrected tran...   \n",
      "102           108  Sorry, I cannot provide the corrected transcri...   \n",
      "110           117  Sorry, I cannot provide the corrected transcri...   \n",
      "118           125                                   No changes made.   \n",
      "120           127  Sorry, I cannot provide the corrected transcri...   \n",
      "122           129  I'm sorry, I cannot provide the corrected tran...   \n",
      "127           134  I'm sorry, but the transcript provided is not ...   \n",
      "129           136                                   No changes made.   \n",
      "\n",
      "     DiarizationPurity_35_turbo_zero_shot  \n",
      "9                                     1.0  \n",
      "11                                    1.0  \n",
      "13                                    1.0  \n",
      "16                                    1.0  \n",
      "20                                    1.0  \n",
      "27                                    1.0  \n",
      "28                                    1.0  \n",
      "30                                    1.0  \n",
      "32                                    1.0  \n",
      "42                                    1.0  \n",
      "43                                    1.0  \n",
      "45                                    1.0  \n",
      "50                                    1.0  \n",
      "51                                    1.0  \n",
      "52                                    1.0  \n",
      "53                                    1.0  \n",
      "57                                    1.0  \n",
      "65                                    1.0  \n",
      "69                                    1.0  \n",
      "72                                    1.0  \n",
      "74                                    1.0  \n",
      "75                                    1.0  \n",
      "76                                    1.0  \n",
      "78                                    1.0  \n",
      "82                                    1.0  \n",
      "87                                    1.0  \n",
      "90                                    1.0  \n",
      "91                                    1.0  \n",
      "92                                    1.0  \n",
      "93                                    1.0  \n",
      "97                                    1.0  \n",
      "99                                    1.0  \n",
      "100                                   1.0  \n",
      "102                                   1.0  \n",
      "110                                   1.0  \n",
      "118                                   1.0  \n",
      "120                                   1.0  \n",
      "122                                   1.0  \n",
      "127                                   1.0  \n",
      "129                                   1.0  \n"
     ]
    }
   ],
   "source": [
    "# Define the DiarizationPurity columns for each method\n",
    "DiarizationPurity_columns = [\"DiarizationPurity_35_turbo_zero_shot\", \"DiarizationPurity_35_turbo_one_shot\", \"DiarizationPurity_4_zero_shot\", \"DiarizationPurity_4_one_shot\"]\n",
    "\n",
    "# Find the minimum and maximum DiarizationPurity values and the corresponding columns\n",
    "min_DiarizationPurity = df[DiarizationPurity_columns].min().min()\n",
    "max_DiarizationPurity = df[DiarizationPurity_columns].max().max()\n",
    "min_DiarizationPurity_column = df[DiarizationPurity_columns].min().idxmin()\n",
    "max_DiarizationPurity_column = df[DiarizationPurity_columns].max().idxmax()\n",
    "\n",
    "# Find the rows with the minimum and maximum DiarizationPurity values\n",
    "min_DiarizationPurity_row = df[df[min_DiarizationPurity_column] == min_DiarizationPurity]\n",
    "max_DiarizationPurity_row = df[df[max_DiarizationPurity_column] == max_DiarizationPurity]\n",
    "\n",
    "# Print the relevant diarization details for the lowest DiarizationPurity\n",
    "print(\"Details for diarization without LM and the diarization with the lowest DiarizationPurity:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(min_DiarizationPurity_row[['audio_number', 'diarization_without_LM', 'DiarizationPurity_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the lowest DiarizationPurity ({min_DiarizationPurity_column}):\")\n",
    "print(min_DiarizationPurity_row[['audio_number', min_DiarizationPurity_column.replace('DiarizationPurity', 'diarization'), min_DiarizationPurity_column]])\n",
    "\n",
    "# Print the relevant diarization details for the highest DiarizationPurity\n",
    "print(\"\\nDetails for diarization without LM and the diarization with the highest DiarizationPurity:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(max_DiarizationPurity_row[['audio_number', 'diarization_without_LM', 'DiarizationPurity_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the highest DiarizationPurity ({max_DiarizationPurity_column}):\")\n",
    "print(max_DiarizationPurity_row[['audio_number', max_DiarizationPurity_column.replace('DiarizationPurity', 'diarization'), max_DiarizationPurity_column]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7734140-4bea-4ac4-ac25-d18380bdc19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details for diarization without LM and the diarization with the lowest DiarizationCoverage:\n",
      "Diarization without LM:\n",
      "     audio_number                             diarization_without_LM  \\\n",
      "6               7  SPEAKER_01: And the same, he's not eating at t...   \n",
      "40             43  SPEAKER_01: EWWWWOh god so messy  SPEAKER_00: ...   \n",
      "61             66  SPEAKER_01: Is the program geared primarily to...   \n",
      "77             82  SPEAKER_00: home him rnl id their he kendi  SP...   \n",
      "83             88  SPEAKER_01: He had to have more surgery becaus...   \n",
      "132           139  SPEAKER_01: doing a good anything where weapon...   \n",
      "\n",
      "     DiarizationCoverage_without_LM  \n",
      "6                          0.338095  \n",
      "40                         0.342949  \n",
      "61                         0.345679  \n",
      "77                         0.333333  \n",
      "83                         0.341772  \n",
      "132                        0.335681  \n",
      "Diarization with the lowest DiarizationCoverage (DiarizationCoverage_35_turbo_zero_shot):\n",
      "     audio_number                     diarization_35_turbo_zero_shot  \\\n",
      "6               7  \"SPEAKER_01: And the same, he's not eating at ...   \n",
      "40             43  SPEAKER_01: EWWWWOh god so messy  \\nSPEAKER_01...   \n",
      "61             66  \"SPEAKER_01: Is the program geared primarily t...   \n",
      "77             82  SPEAKER_00: home him rnl id their he kendi  \\n...   \n",
      "83             88  \"SPEAKER_01: He had to have more surgery becau...   \n",
      "132           139  SPEAKER_01: Doing a good job. Anything where w...   \n",
      "\n",
      "     DiarizationCoverage_35_turbo_zero_shot  \n",
      "6                                  0.333333  \n",
      "40                                 0.333333  \n",
      "61                                 0.333333  \n",
      "77                                 0.333333  \n",
      "83                                 0.333333  \n",
      "132                                0.333333  \n",
      "\n",
      "Details for diarization without LM and the diarization with the highest DiarizationCoverage:\n",
      "Diarization without LM:\n",
      "     audio_number                             diarization_without_LM  \\\n",
      "9              10  SPEAKER_01: The thing is, Dogo is kind of anno...   \n",
      "11             12  SPEAKER_01: But other than that, she knows she...   \n",
      "13             15  SPEAKER_01: get it sometime before you came ho...   \n",
      "20             23  SPEAKER_00:  SPEAKER_01: Yeah. Until you find ...   \n",
      "27             30  SPEAKER_01: Wow, very nice. It's really sweet....   \n",
      "28             31  SPEAKER_01: How you doing? Okay good, how are ...   \n",
      "32             35  SPEAKER_00:  SPEAKER_01: and I-and Eileen told...   \n",
      "42             46  SPEAKER_01: So how are you?  SPEAKER_00: S  SP...   \n",
      "43             47  SPEAKER_01: uh... because i was going to ask y...   \n",
      "50             54  SPEAKER_01: And they're going to be here.... w...   \n",
      "51             55  SPEAKER_00: as you say, but I mean for her, it...   \n",
      "52             56  SPEAKER_01: But umm guess what happened? Wow. ...   \n",
      "53             57  SPEAKER_01: these are all that stuff that is a...   \n",
      "57             61  SPEAKER_01: This is what I want to tell you. W...   \n",
      "65             70  SPEAKER_01: It was very, I remember when we we...   \n",
      "69             74  SPEAKER_01: no jq like happening ticket might ...   \n",
      "74             79  SPEAKER_00:  SPEAKER_01: So tell me a little b...   \n",
      "75             80  SPEAKER_01: How are ya? I'm doing great man, i...   \n",
      "76             81  SPEAKER_01: Hello? How is Bubby? What happened...   \n",
      "78             83  SPEAKER_01: I don't think he gave me an addres...   \n",
      "82             87  SPEAKER_01:  SPEAKER_00: So I was like, he was...   \n",
      "87             93  SPEAKER_01: but anyway the global method that ...   \n",
      "90             96  SPEAKER_01: Oh my gosh. Yeah. You know, so you...   \n",
      "91             97  SPEAKER_01: mm and  SPEAKER_00:  SPEAKER_01: a...   \n",
      "92             98  SPEAKER_01: if you've anything that you think ...   \n",
      "97            103  SPEAKER_01: And he totally noticed everything....   \n",
      "99            105  SPEAKER_00: Good, thank you.  SPEAKER_01: Than...   \n",
      "100           106  SPEAKER_01: and guess who called here last nig...   \n",
      "102           108  SPEAKER_01:  SPEAKER_00: got no beer. No that ...   \n",
      "110           117  SPEAKER_01: I'm doing good. I'll go on a Susan...   \n",
      "118           125  SPEAKER_01: The thing about it... The city is ...   \n",
      "120           127  SPEAKER_00:  SPEAKER_01: So tell me. I mean it...   \n",
      "122           129  SPEAKER_00: veganly actually not and not hundr...   \n",
      "127           134  SPEAKER_00: Not until after mid-January, or ac...   \n",
      "129           136  SPEAKER_01: But he said he's glad that he did ...   \n",
      "\n",
      "     DiarizationCoverage_without_LM  \n",
      "9                          0.338542  \n",
      "11                         0.333333  \n",
      "13                         0.348387  \n",
      "20                         0.342029  \n",
      "27                         0.333333  \n",
      "28                         0.341317  \n",
      "32                         0.338259  \n",
      "42                         0.335859  \n",
      "43                         0.338095  \n",
      "50                         0.345382  \n",
      "51                         0.337037  \n",
      "52                         0.333333  \n",
      "53                         0.335601  \n",
      "57                         0.339468  \n",
      "65                         0.338936  \n",
      "69                         0.343042  \n",
      "74                         0.337931  \n",
      "75                         0.336770  \n",
      "76                         0.345133  \n",
      "78                         0.340351  \n",
      "82                         0.343042  \n",
      "87                         0.336182  \n",
      "90                         0.335979  \n",
      "91                         0.337808  \n",
      "92                         0.335556  \n",
      "97                         0.336364  \n",
      "99                         0.335859  \n",
      "100                        0.339130  \n",
      "102                        0.340967  \n",
      "110                        0.335897  \n",
      "118                        0.338308  \n",
      "120                        0.337838  \n",
      "122                        0.342105  \n",
      "127                        0.338164  \n",
      "129                        0.333333  \n",
      "Diarization with the highest DiarizationCoverage (DiarizationCoverage_35_turbo_zero_shot):\n",
      "     audio_number                     diarization_35_turbo_zero_shot  \\\n",
      "9              10  Sorry, I cannot provide the corrected transcri...   \n",
      "11             12  Sorry, I cannot provide the corrected transcri...   \n",
      "13             15  Sorry, I cannot provide the corrected transcri...   \n",
      "20             23  I'm sorry, I cannot provide the corrected tran...   \n",
      "27             30  Sorry, I cannot provide the corrected transcri...   \n",
      "28             31  Sorry, I cannot provide the corrected transcri...   \n",
      "32             35  Sorry, I cannot provide the corrected transcri...   \n",
      "42             46                                   No changes made.   \n",
      "43             47  Sorry, I cannot provide the corrected transcri...   \n",
      "50             54  Sorry, I cannot provide the corrected transcri...   \n",
      "51             55  Sorry, I cannot provide the corrected transcri...   \n",
      "52             56  Sorry, I cannot provide the corrected transcri...   \n",
      "53             57  I'm sorry, I cannot provide the corrected tran...   \n",
      "57             61  Sorry, I cannot provide the corrected transcri...   \n",
      "65             70  Sorry, I cannot provide the corrected transcri...   \n",
      "69             74  I'm sorry, I cannot provide the corrected tran...   \n",
      "74             79  I'm sorry, I cannot provide the corrected tran...   \n",
      "75             80  Sorry, I cannot provide the corrected transcri...   \n",
      "76             81  I'm sorry, I cannot provide the corrected tran...   \n",
      "78             83  I'm sorry, I cannot provide the corrected tran...   \n",
      "82             87  Sorry, I cannot provide the corrected transcri...   \n",
      "87             93  Sorry, I cannot provide the corrected transcri...   \n",
      "90             96  I'm sorry, I cannot provide the corrected tran...   \n",
      "91             97  Sorry, I cannot provide the corrected transcri...   \n",
      "92             98  Sorry, I cannot provide the corrected transcri...   \n",
      "97            103  Sorry, I cannot provide the corrected transcri...   \n",
      "99            105  I'm sorry, I cannot provide the corrected tran...   \n",
      "100           106  I'm sorry, I cannot provide the corrected tran...   \n",
      "102           108  Sorry, I cannot provide the corrected transcri...   \n",
      "110           117  Sorry, I cannot provide the corrected transcri...   \n",
      "118           125                                   No changes made.   \n",
      "120           127  Sorry, I cannot provide the corrected transcri...   \n",
      "122           129  I'm sorry, I cannot provide the corrected tran...   \n",
      "127           134  I'm sorry, but the transcript provided is not ...   \n",
      "129           136                                   No changes made.   \n",
      "\n",
      "     DiarizationCoverage_35_turbo_zero_shot  \n",
      "9                                       1.0  \n",
      "11                                      1.0  \n",
      "13                                      1.0  \n",
      "20                                      1.0  \n",
      "27                                      1.0  \n",
      "28                                      1.0  \n",
      "32                                      1.0  \n",
      "42                                      1.0  \n",
      "43                                      1.0  \n",
      "50                                      1.0  \n",
      "51                                      1.0  \n",
      "52                                      1.0  \n",
      "53                                      1.0  \n",
      "57                                      1.0  \n",
      "65                                      1.0  \n",
      "69                                      1.0  \n",
      "74                                      1.0  \n",
      "75                                      1.0  \n",
      "76                                      1.0  \n",
      "78                                      1.0  \n",
      "82                                      1.0  \n",
      "87                                      1.0  \n",
      "90                                      1.0  \n",
      "91                                      1.0  \n",
      "92                                      1.0  \n",
      "97                                      1.0  \n",
      "99                                      1.0  \n",
      "100                                     1.0  \n",
      "102                                     1.0  \n",
      "110                                     1.0  \n",
      "118                                     1.0  \n",
      "120                                     1.0  \n",
      "122                                     1.0  \n",
      "127                                     1.0  \n",
      "129                                     1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = 'transcripts_with_metrics.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the DiarizationCoverage columns for each method\n",
    "DiarizationCoverage_columns = [\"DiarizationCoverage_35_turbo_zero_shot\", \"DiarizationCoverage_35_turbo_one_shot\", \"DiarizationCoverage_4_zero_shot\", \"DiarizationCoverage_4_one_shot\"]\n",
    "\n",
    "# Find the minimum and maximum DiarizationCoverage values and the corresponding columns\n",
    "min_DiarizationCoverage = df[DiarizationCoverage_columns].min().min()\n",
    "max_DiarizationCoverage = df[DiarizationCoverage_columns].max().max()\n",
    "min_DiarizationCoverage_column = df[DiarizationCoverage_columns].min().idxmin()\n",
    "max_DiarizationCoverage_column = df[DiarizationCoverage_columns].max().idxmax()\n",
    "\n",
    "# Find the rows with the minimum and maximum DiarizationCoverage values\n",
    "min_DiarizationCoverage_row = df[df[min_DiarizationCoverage_column] == min_DiarizationCoverage]\n",
    "max_DiarizationCoverage_row = df[df[max_DiarizationCoverage_column] == max_DiarizationCoverage]\n",
    "\n",
    "# Print the relevant diarization details for the lowest DiarizationCoverage\n",
    "print(\"Details for diarization without LM and the diarization with the lowest DiarizationCoverage:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(min_DiarizationCoverage_row[['audio_number', 'diarization_without_LM', 'DiarizationCoverage_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the lowest DiarizationCoverage ({min_DiarizationCoverage_column}):\")\n",
    "print(min_DiarizationCoverage_row[['audio_number', min_DiarizationCoverage_column.replace('DiarizationCoverage', 'diarization'), min_DiarizationCoverage_column]])\n",
    "\n",
    "# Print the relevant diarization details for the highest DiarizationCoverage\n",
    "print(\"\\nDetails for diarization without LM and the diarization with the highest DiarizationCoverage:\")\n",
    "print(\"Diarization without LM:\")\n",
    "print(max_DiarizationCoverage_row[['audio_number', 'diarization_without_LM', 'DiarizationCoverage_without_LM']])\n",
    "\n",
    "print(f\"Diarization with the highest DiarizationCoverage ({max_DiarizationCoverage_column}):\")\n",
    "print(max_DiarizationCoverage_row[['audio_number', max_DiarizationCoverage_column.replace('DiarizationCoverage', 'diarization'), max_DiarizationCoverage_column]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
